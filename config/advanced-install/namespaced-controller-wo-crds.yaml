apiVersion: v1
kind: ServiceAccount
metadata:
  name: numaflow-sa
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  labels:
    app.kubernetes.io/component: controller-manager
    app.kubernetes.io/name: numaflow-controller-manager
    app.kubernetes.io/part-of: numaflow
  name: numaflow-role
rules:
- apiGroups:
  - numaflow.numaproj.io
  resources:
  - interstepbufferservices
  - interstepbufferservices/finalizers
  - interstepbufferservices/status
  - pipelines
  - pipelines/finalizers
  - pipelines/status
  - vertices
  - vertices/finalizers
  - vertices/status
  - vertices/scale
  - monovertices
  - monovertices/finalizers
  - monovertices/status
  - monovertices/scale
  verbs:
  - create
  - delete
  - deletecollection
  - get
  - list
  - patch
  - update
  - watch
- apiGroups:
  - coordination.k8s.io
  resources:
  - leases
  verbs:
  - get
  - list
  - watch
  - create
  - update
  - patch
  - delete
- apiGroups:
  - ""
  resources:
  - events
  verbs:
  - create
  - patch
- apiGroups:
  - ""
  resources:
  - pods
  - pods/exec
  - configmaps
  - services
  - persistentvolumeclaims
  verbs:
  - create
  - get
  - list
  - watch
  - update
  - patch
  - delete
- apiGroups:
  - ""
  resources:
  - secrets
  verbs:
  - create
  - get
  - list
  - update
  - patch
  - delete
- apiGroups:
  - apps
  resources:
  - deployments
  - statefulsets
  verbs:
  - create
  - get
  - list
  - watch
  - update
  - patch
  - delete
- apiGroups:
  - batch
  resources:
  - jobs
  verbs:
  - create
  - get
  - list
  - watch
  - update
  - patch
  - delete
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  labels:
    app.kubernetes.io/component: controller-manager
    app.kubernetes.io/name: numaflow-controller-manager
    app.kubernetes.io/part-of: numaflow
  name: numaflow-role-binding
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: numaflow-role
subjects:
- kind: ServiceAccount
  name: numaflow-sa
---
apiVersion: v1
data:
  namespaced: "true"
  server.disable.auth: "true"
kind: ConfigMap
metadata:
  name: numaflow-cmd-params-config
---
apiVersion: v1
data:
  controller-config.yaml: "# Within a cluster, setting \"instance\" can be used to
    run multiple Numaflow controllers. \n# If configured, the controller will only
    watch the objects having an annotation with the key \"numaflow.numaproj.io/instance\"
    and the corresponding value.\n# If not configured (or empty string), the controller
    will watch all objects.\ninstance: \"\"\ndefaults:\n  containerResources: |\n
    \   requests:\n      memory: \"128Mi\"\n      cpu: \"100m\"\nisbsvc:\n  redis:\n
    \   # Default Redis settings, could be overridden by InterStepBufferService specs\n
    \   settings:\n      # Redis config shared by both master and replicas\n      redis:
    |\n        min-replicas-to-write 1\n        # Disable RDB persistence, AOF persistence
    already enabled.\n        save \"\"\n        # Enable AOF https://redis.io/topics/persistence#append-only-file\n
    \       appendonly yes\n        auto-aof-rewrite-percentage 100\n        auto-aof-rewrite-min-size
    64mb\n        maxmemory 512mb\n        maxmemory-policy allkeys-lru\n      # Special
    config only used by master\n      master: \"\"\n      # Special config only used
    by replicas\n      replica: \"\"\n      # Sentinel config\n      sentinel: |\n
    \       sentinel down-after-milliseconds mymaster 10000\n        sentinel failover-timeout
    mymaster 2000\n        sentinel parallel-syncs mymaster 1\n    versions:\n    -
    version: 7.0.11\n      redisImage: bitnami/redis:7.0.11-debian-11-r3\n      sentinelImage:
    bitnami/redis-sentinel:7.0.11-debian-11-r3\n      redisExporterImage: bitnami/redis-exporter:1.50.0-debian-11-r4\n
    \     initContainerImage: debian:latest\n    - version: 7.0.15\n      redisImage:
    bitnami/redis:7.0.15-debian-11-r2\n      sentinelImage: bitnami/redis-sentinel:7.0.15-debian-11-r2\n
    \     redisExporterImage: bitnami/redis-exporter:1.56.0-debian-11-r2\n      initContainerImage:
    debian:latest\n  jetstream:\n    # Default JetStream settings, could be overridden
    by InterStepBufferService specs\n    settings: |\n      # https://docs.nats.io/running-a-nats-service/configuration#limits\n
    \     # Only support to configure \"max_payload\".\n      # Max payload size in
    bytes, defaults to 1 MB. It is not recommended to use values over 8MB but max_payload
    can be set up to 64MB.\n      max_payload: 1048576\n      # https://docs.nats.io/running-a-nats-service/configuration#jetstream\n
    \     # Only configure \"max_memory_store\" or \"max_file_store\", do not set
    \"store_dir\" as it has been hardcoded.\n      # e.g. 1G. -1 means no limit, up
    to 75% of available memory. This only take effect for streams created using memory
    storage.\n      max_memory_store: -1\n      # e.g. 20G. -1 means no limit, Up
    to 1TB if available\n      max_file_store: 1TB\n    bufferConfig: |\n      # The
    default properties of the buffers (streams) to be created in this JetStream service\n
    \     stream:\n        # 0: Limits, 1: Interest, 2: WorkQueue\n        retention:
    0\n        maxMsgs: 100000\n        maxAge: 72h\n        maxBytes: -1\n        #
    0: File, 1: Memory\n        storage: 0\n        replicas: 3\n        duplicates:
    60s\n      # The default consumer properties for the created streams\n      consumer:\n
    \       ackWait: 60s\n        maxAckPending: 25000\n      otBucket:\n        maxValueSize:
    0\n        history: 1\n        ttl: 3h\n        maxBytes: 0\n        # 0: File,
    1: Memory\n        storage: 0\n        replicas: 3\n      procBucket:\n        maxValueSize:
    0\n        history: 1\n        ttl: 72h\n        maxBytes: 0\n        # 0: File,
    1: Memory\n        storage: 0\n        replicas: 3\n    versions:\n    - version:
    latest\n      natsImage: nats:2.10.17\n      metricsExporterImage: natsio/prometheus-nats-exporter:0.9.1\n
    \     configReloaderImage: natsio/nats-server-config-reloader:0.7.0\n      startCommand:
    /nats-server\n    - version: 2.8.1\n      natsImage: nats:2.8.1\n      metricsExporterImage:
    natsio/prometheus-nats-exporter:0.9.1\n      configReloaderImage: natsio/nats-server-config-reloader:0.7.0\n
    \     startCommand: /nats-server\n    - version: 2.8.1-alpine\n      natsImage:
    nats:2.8.1-alpine\n      metricsExporterImage: natsio/prometheus-nats-exporter:0.9.1\n
    \     configReloaderImage: natsio/nats-server-config-reloader:0.7.0\n      startCommand:
    nats-server\n    - version: 2.8.3\n      natsImage: nats:2.8.3\n      metricsExporterImage:
    natsio/prometheus-nats-exporter:0.9.1\n      configReloaderImage: natsio/nats-server-config-reloader:0.7.0\n
    \     startCommand: /nats-server\n    - version: 2.8.3-alpine\n      natsImage:
    nats:2.8.3-alpine\n      metricsExporterImage: natsio/prometheus-nats-exporter:0.9.1\n
    \     configReloaderImage: natsio/nats-server-config-reloader:0.7.0\n      startCommand:
    nats-server\n    - version: 2.9.0\n      natsImage: nats:2.9.0\n      metricsExporterImage:
    natsio/prometheus-nats-exporter:0.9.1\n      configReloaderImage: natsio/nats-server-config-reloader:0.7.0\n
    \     startCommand: /nats-server\n    - version: 2.9.0-alpine\n      natsImage:
    nats:2.9.0-alpine\n      metricsExporterImage: natsio/prometheus-nats-exporter:0.9.1\n
    \     configReloaderImage: natsio/nats-server-config-reloader:0.7.0\n      startCommand:
    nats-server\n    - version: 2.9.6\n      natsImage: nats:2.9.6\n      metricsExporterImage:
    natsio/prometheus-nats-exporter:0.9.1\n      configReloaderImage: natsio/nats-server-config-reloader:0.7.0\n
    \     startCommand: /nats-server\n    - version: 2.9.8\n      natsImage: nats:2.9.8\n
    \     metricsExporterImage: natsio/prometheus-nats-exporter:0.9.1\n      configReloaderImage:
    natsio/nats-server-config-reloader:0.7.0\n      startCommand: /nats-server\n    -
    version: 2.9.15\n      natsImage: nats:2.9.15\n      metricsExporterImage: natsio/prometheus-nats-exporter:0.9.1\n
    \     configReloaderImage: natsio/nats-server-config-reloader:0.7.0\n      startCommand:
    /nats-server\n    - version: 2.10.3\n      natsImage: nats:2.10.3\n      metricsExporterImage:
    natsio/prometheus-nats-exporter:0.9.1\n      configReloaderImage: natsio/nats-server-config-reloader:0.7.0\n
    \     startCommand: /nats-server\n    - version: 2.10.11\n      natsImage: nats:2.10.11\n
    \     metricsExporterImage: natsio/prometheus-nats-exporter:0.9.1\n      configReloaderImage:
    natsio/nats-server-config-reloader:0.7.0\n      startCommand: /nats-server\n    -
    version: 2.10.17\n      natsImage: nats:2.10.17\n      metricsExporterImage: natsio/prometheus-nats-exporter:0.9.1\n
    \     configReloaderImage: natsio/nats-server-config-reloader:0.7.0\n      startCommand:
    /nats-server\n"
kind: ConfigMap
metadata:
  name: numaflow-controller-config
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: numaflow-controller
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/component: controller-manager
      app.kubernetes.io/name: controller-manager
      app.kubernetes.io/part-of: numaflow
  template:
    metadata:
      labels:
        app.kubernetes.io/component: controller-manager
        app.kubernetes.io/name: controller-manager
        app.kubernetes.io/part-of: numaflow
    spec:
      containers:
      - args:
        - controller
        env:
        - name: NUMAFLOW_IMAGE
          value: quay.io/numaproj/numaflow:latest
        - name: NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        - name: NUMAFLOW_CONTROLLER_NAMESPACED
          valueFrom:
            configMapKeyRef:
              key: namespaced
              name: numaflow-cmd-params-config
              optional: true
        - name: NUMAFLOW_CONTROLLER_MANAGED_NAMESPACE
          valueFrom:
            configMapKeyRef:
              key: managed.namespace
              name: numaflow-cmd-params-config
              optional: true
        - name: NUMAFLOW_LEADER_ELECTION_DISABLED
          valueFrom:
            configMapKeyRef:
              key: controller.leader.election.disabled
              name: numaflow-cmd-params-config
              optional: true
        - name: NUMAFLOW_LEADER_ELECTION_LEASE_DURATION
          valueFrom:
            configMapKeyRef:
              key: controller.leader.election.lease.duration
              name: numaflow-cmd-params-config
              optional: true
        - name: NUMAFLOW_LEADER_ELECTION_LEASE_RENEW_DEADLINE
          valueFrom:
            configMapKeyRef:
              key: controller.leader.election.lease.renew.deadline
              name: numaflow-cmd-params-config
              optional: true
        - name: NUMAFLOW_LEADER_ELECTION_LEASE_RENEW_PERIOD
          valueFrom:
            configMapKeyRef:
              key: controller.leader.election.lease.renew.period
              name: numaflow-cmd-params-config
              optional: true
        image: quay.io/numaproj/numaflow:latest
        imagePullPolicy: Always
        livenessProbe:
          httpGet:
            path: /healthz
            port: 8081
          initialDelaySeconds: 3
          periodSeconds: 3
        name: controller-manager
        ports:
        - containerPort: 9090
          name: metrics
        readinessProbe:
          httpGet:
            path: /readyz
            port: 8081
          initialDelaySeconds: 3
          periodSeconds: 3
        resources:
          limits:
            cpu: 500m
            memory: 1024Mi
          requests:
            cpu: 100m
            memory: 200Mi
        volumeMounts:
        - mountPath: /etc/numaflow
          name: controller-config-volume
      securityContext:
        runAsNonRoot: true
        runAsUser: 9737
      serviceAccountName: numaflow-sa
      volumes:
      - configMap:
          name: numaflow-controller-config
        name: controller-config-volume
