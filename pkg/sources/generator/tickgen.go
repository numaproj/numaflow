/*
Copyright 2022 The Numaproj Authors.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

// Package generator contains an implementation of an in-memory generator that generates
// payloads in json format.
package generator

import (
	"context"
	"crypto/rand"
	"encoding/base64"
	"encoding/json"
	"fmt"
	rand2 "math/rand"
	"time"

	"go.uber.org/zap"

	dfv1 "github.com/numaproj/numaflow/pkg/apis/numaflow/v1alpha1"
	"github.com/numaproj/numaflow/pkg/isb"
	"github.com/numaproj/numaflow/pkg/metrics"
	"github.com/numaproj/numaflow/pkg/shared/logging"
	"github.com/numaproj/numaflow/pkg/sources/sourcer"
)

type Data struct {
	Value uint64 `json:"value,omitempty"`
	// only to ensure a desired message size
	Padding []byte `json:"padding,omitempty"`
}

// payload generated by the generator function
// look at newReadMessage function
type payload struct {
	Data      Data
	Createdts int64
}

// record is payload with offset
// internal construct of this package
type record struct {
	data   []byte
	offset int64
	key    string
	ts     int64
}

var recordGenerator = func(size int32, value *uint64, createdTS int64) ([]byte, error) {
	data := Data{}
	if value != nil {
		data.Value = *value
	} else {
		data.Value = uint64(createdTS)
	}
	size = size - 8
	if size > 0 {
		// padding to guarantee the size of the message
		b := make([]byte, size)
		_, _ = rand.Read(b) // we do not care about failures here.
		data.Padding = b
	}

	r := payload{Data: data, Createdts: createdTS}
	return json.Marshal(r)
}

type memGen struct {
	srcChan        chan record                                 // srcChan provides a go channel that supplies generated data
	rpu            int                                         // rpu - records per time unit
	keyCount       int32                                       // keyCount is the number of unique keys in the payload
	value          *uint64                                     // value is the optional uint64 number that can be set in the payload
	msgSize        int32                                       // msgSize is the size of each generated message
	timeunit       time.Duration                               // timeunit - ticker will fire once per timeunit
	genFn          func(int32, *uint64, int64) ([]byte, error) // genFn function that generates a payload as a byte array
	vertexName     string                                      // name is the name of the source vertex
	pipelineName   string                                      // pipelineName is the name of the pipeline
	readTimeout    time.Duration                               // read timeout for the reader
	vertexInstance *dfv1.VertexInstance                        // vertex instance
	jitter         time.Duration
	logger         *zap.SugaredLogger
}

type Option func(*memGen) error

// WithReadTimeout sets the read timeout for the reader.
func WithReadTimeout(timeout time.Duration) Option {
	return func(o *memGen) error {
		o.readTimeout = timeout
		return nil
	}
}

// NewMemGen function creates an instance of generator source reader.
func NewMemGen(ctx context.Context, vertexInstance *dfv1.VertexInstance, opts ...Option) (sourcer.SourceReader, error) {

	logger := logging.FromContext(ctx)

	// minimal CRDs don't have defaults
	rpu := 5
	if vertexInstance.Vertex.Spec.Source.Generator.RPU != nil {
		rpu = int(*(vertexInstance.Vertex.Spec.Source.Generator.RPU))
	}
	msgSize := int32(8)
	if vertexInstance.Vertex.Spec.Source.Generator.MsgSize != nil {
		msgSize = *vertexInstance.Vertex.Spec.Source.Generator.MsgSize
	}
	timeunit := time.Second
	if vertexInstance.Vertex.Spec.Source.Generator.Duration != nil {
		timeunit = vertexInstance.Vertex.Spec.Source.Generator.Duration.Duration
	}
	keyCount := int32(1)
	if vertexInstance.Vertex.Spec.Source.Generator.KeyCount != nil {
		keyCount = *(vertexInstance.Vertex.Spec.Source.Generator.KeyCount)
	}
	var value *uint64
	if vertexInstance.Vertex.Spec.Source.Generator.Value != nil {
		value = vertexInstance.Vertex.Spec.Source.Generator.Value
	}

	var jitter time.Duration
	if vertexInstance.Vertex.Spec.Source.Generator.Jitter != nil {
		jitter = vertexInstance.Vertex.Spec.Source.Generator.Jitter.Duration
	}

	var genFunction = recordGenerator
	if vertexInstance.Vertex.Spec.Source.Generator.ValueBlob != nil {
		logger.Info("ValueBlob was set, using provided value instead of randomly generated data")
		emitBytes, err := base64.StdEncoding.DecodeString(*vertexInstance.Vertex.Spec.Source.Generator.ValueBlob)
		if err != nil {
			retErr := fmt.Errorf("error decoding provided ValueBlob as base64, cannot initialize generator. Decode error: %w", err)
			return nil, retErr
		}

		// Custom generator function to return provided value. Input arguments are not used, but are preserved
		// to maintain consistent interface with recordGenerator
		genFunction = func(size int32, value *uint64, createdTS int64) ([]byte, error) {
			return emitBytes, nil
		}
	}

	genSrc := &memGen{
		rpu:            rpu,
		keyCount:       keyCount,
		value:          value,
		msgSize:        msgSize,
		timeunit:       timeunit,
		vertexName:     vertexInstance.Vertex.Spec.Name,
		pipelineName:   vertexInstance.Vertex.Spec.PipelineName,
		genFn:          genFunction,
		vertexInstance: vertexInstance,
		srcChan:        make(chan record, rpu*int(keyCount)*5),
		readTimeout:    3 * time.Second, // default timeout
		jitter:         jitter,
		logger:         logger,
	}

	for _, o := range opts {
		if err := o(genSrc); err != nil {
			return nil, err
		}
	}

	// start the generator
	go genSrc.generator(ctx, genSrc.rpu, genSrc.timeunit)

	return genSrc, nil
}

// GetName returns the name of the source
func (mg *memGen) GetName() string {
	return mg.vertexName
}

// Partitions returns the partitions for the source.
func (mg *memGen) Partitions(context.Context) []int32 {
	return []int32{mg.vertexInstance.Replica}
}

func (mg *memGen) Read(_ context.Context, count int64) ([]*isb.ReadMessage, error) {
	msgs := make([]*isb.ReadMessage, 0, count)
	// timeout should not be re-triggered for every run of the for loop. it is for the entire Read() call.
	timeout := time.After(mg.readTimeout)
loop:
	for i := int64(0); i < count; i++ {
		// since the Read call is blocking, and runs in an infinite loop,
		// we implement Read With Wait semantics
		select {
		case r := <-mg.srcChan:
			tickgenSourceReadCount.With(map[string]string{metrics.LabelVertex: mg.vertexName, metrics.LabelPipeline: mg.pipelineName}).Inc()
			msgs = append(msgs, mg.newReadMessage(r.key, r.data, r.offset, r.ts))
		case <-timeout:
			mg.logger.Infow("Timed out waiting for messages to read.", zap.Duration("waited", mg.readTimeout))
			break loop
		}
	}
	return msgs, nil
}

func (mg *memGen) Pending(_ context.Context) (int64, error) {
	return isb.PendingNotAvailable, nil
}

// Ack acknowledges an array of offset.
func (mg *memGen) Ack(_ context.Context, offsets []isb.Offset) []error {
	return make([]error, len(offsets))
}

func (mg *memGen) Close() error {
	return nil
}

func (mg *memGen) newWorker(ctx context.Context, rate int) func(chan time.Time, chan struct{}) {
	return func(tickChan chan time.Time, done chan struct{}) {
		defer func() {
			// empty any pending ticks
			if len(tickChan) > 0 {
				mg.logger.Info("emptying any pending ticks")
				for len(tickChan) > 0 {
					<-tickChan
				}
			}
		}()
		defer close(done)
		defer close(mg.srcChan)

		for {
			select {
			case <-ctx.Done():
				return
			case ts := <-tickChan:
				tickgenSourceCount.With(map[string]string{metrics.LabelVertex: mg.vertexName, metrics.LabelPipeline: mg.pipelineName})
				// we would generate all the keys in a round robin fashion
				// even if there are multiple pods, all the pods will generate same keys in the same order.
				// TODO: alternatively, we could also think about generating a subset of keys per pod.
				t := ts.UnixNano()
				for i := 0; i < rate; i++ {
					for k := int32(0); k < mg.keyCount; k++ {
						key := fmt.Sprintf("key-%d-%d", mg.vertexInstance.Replica, k)
						d, err := mg.genFn(mg.msgSize, mg.value, t)
						if err != nil {
							mg.logger.Errorw("Error while generating the record, skipping the record", zap.Error(err))
							continue
						}
						r := record{data: d, offset: time.Now().UTC().UnixNano(), key: key, ts: t}
						select {
						case <-ctx.Done():
							mg.logger.Info("Context.Done is called. returning from the inner function")
							return
						case mg.srcChan <- r:
						}
					}
				}
			}
		}
	}
}

// generator fires once per time unit and generates records and writes them to the channel
func (mg *memGen) generator(ctx context.Context, rate int, timeunit time.Duration) {
	// capping the rate to 10000 msgs/sec
	if rate > 10000 {
		mg.logger.Infow("Capping the rate to 10000 msg/sec. rate has been changed from %d to 10000", rate)
		rate = 10000
	}

	tickChan := make(chan time.Time, 1000)
	doneChan := make(chan struct{})

	// make sure that there is only one worker all the time.
	// even when there is back pressure, max number of go routines inflight should be 1.
	// at the same time, we don't want to miss any ticks that cannot be processed.
	worker := mg.newWorker(ctx, rate)
	go worker(tickChan, doneChan)

	ticker := time.NewTicker(timeunit)
	defer ticker.Stop()

	for {
		select {
		// we don't need to wait for ticker to fire to return
		// when the context closes
		case <-ctx.Done():
			mg.logger.Info("Context.Done is called. exiting generator loop.")
			<-doneChan
			return
		case ts := <-ticker.C:
			tickChan <- ts
		}
	}
}

func (mg *memGen) newReadMessage(key string, payload []byte, offset int64, et int64) *isb.ReadMessage {
	readOffset := isb.NewSimpleIntPartitionOffset(offset, mg.vertexInstance.Replica)
	msg := isb.Message{
		Header: isb.Header{
			// TODO: insert the right time based on the generator
			MessageInfo: isb.MessageInfo{EventTime: timeFromNanos(et, mg.jitter)},
			ID:          readOffset.String(),
			Keys:        []string{key},
		},
		Body: isb.Body{Payload: payload},
	}

	return &isb.ReadMessage{
		ReadOffset: readOffset,
		Message:    msg,
	}
}

func timeFromNanos(etime int64, jitter time.Duration) time.Time {
	// un-parseable json or invalid time format will be substituted with current time.
	if etime > 0 {
		updatedTs := time.Unix(0, etime)
		if jitter.Seconds() == 0 {
			return updatedTs
		}
		d := rand2.Intn(int(jitter.Seconds()))
		return updatedTs.Add(time.Duration(-d) * time.Second)
	}
	return time.Now()
}
